{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d3393f-271b-49d6-a328-bd116dfca477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from textblob import Word\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10458fa-89d7-4a9c-a1b3-2ab1b846113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        filename  \\\n",
      "0                        pdf1_data_scientist.pdf   \n",
      "1                         pdf2_data_engineer.pdf   \n",
      "2                          pdf3_data_analyst.pdf   \n",
      "3                  pdf4_full_stack_developer.pdf   \n",
      "4                     pdf5_software_engineer.pdf   \n",
      "5               pdf6_python_django_developer.pdf   \n",
      "6                           pdf7_QA_engineer.pdf   \n",
      "7                       pdf8_quality_analyst.pdf   \n",
      "8  pdf9_cyber_security_consultant_specialist.pdf   \n",
      "\n",
      "                                         description  \n",
      "0  Data Scientist Ascendion Bangalore Urban Updat...  \n",
      "1  Data Engineer Ascendion Bangalore Urban Update...  \n",
      "2  Data Analyst H&M Bengaluru Updated On: Sep 3, ...  \n",
      "3  Full Stack Developer D Square Consulting Servi...  \n",
      "4  Software Engineer Microsoft Pan India Updated ...  \n",
      "5  Python Django Developer VegaStack (PeerXP) Ban...  \n",
      "6  QA Engineer Adp Chennai Updated On: Sep 1, 202...  \n",
      "7  Quality Analyst Evon Technologies Dehradun Upd...  \n",
      "8  Cyber Security  Consultant Specialist HSBC Pun...  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('job_desc.csv')\n",
    "test = test.dropna()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2666dde4-b8de-432e-9c56-47c93917aba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        filename  \\\n",
      "0                        pdf1_data_scientist.pdf   \n",
      "1                         pdf2_data_engineer.pdf   \n",
      "2                          pdf3_data_analyst.pdf   \n",
      "3                  pdf4_full_stack_developer.pdf   \n",
      "4                     pdf5_software_engineer.pdf   \n",
      "5               pdf6_python_django_developer.pdf   \n",
      "6                           pdf7_QA_engineer.pdf   \n",
      "7                       pdf8_quality_analyst.pdf   \n",
      "8  pdf9_cyber_security_consultant_specialist.pdf   \n",
      "\n",
      "                                         description  \n",
      "0  data scientist ascendion bangalore urban updat...  \n",
      "1  data engineer ascendion bangalore urban update...  \n",
      "2  data analyst h m bengaluru updated on sep 3 20...  \n",
      "3  full stack developer d square consulting servi...  \n",
      "4  software engineer microsoft pan india updated ...  \n",
      "5  python django developer vegastack peerxp banga...  \n",
      "6  qa engineer adp chennai updated on sep 1 2025 ...  \n",
      "7  quality analyst evon technologies dehradun upd...  \n",
      "8  cyber security consultant specialist hsbc pune...  \n"
     ]
    }
   ],
   "source": [
    "test['description'] = test['description'].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    "test['description'] =test['description'].str.replace(r'[^\\w\\s]',' ',regex=True)\n",
    "print(test)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e26ac8a-0070-4d6b-b33c-bf09847c162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['description']=test['description'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73573318-e23b-4096-8b51-7217a496aa75",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'job_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m jda=test.groupby([\u001b[33m'\u001b[39m\u001b[33mjob_title\u001b[39m\u001b[33m'\u001b[39m]).sum().reset_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\core\\frame.py:9190\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[32m   9191\u001b[39m     obj=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   9192\u001b[39m     keys=by,\n\u001b[32m   9193\u001b[39m     axis=axis,\n\u001b[32m   9194\u001b[39m     level=level,\n\u001b[32m   9195\u001b[39m     as_index=as_index,\n\u001b[32m   9196\u001b[39m     sort=sort,\n\u001b[32m   9197\u001b[39m     group_keys=group_keys,\n\u001b[32m   9198\u001b[39m     observed=observed,\n\u001b[32m   9199\u001b[39m     dropna=dropna,\n\u001b[32m   9200\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1330\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1327\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m     grouper, exclusions, obj = get_grouper(\n\u001b[32m   1331\u001b[39m         obj,\n\u001b[32m   1332\u001b[39m         keys,\n\u001b[32m   1333\u001b[39m         axis=axis,\n\u001b[32m   1334\u001b[39m         level=level,\n\u001b[32m   1335\u001b[39m         sort=sort,\n\u001b[32m   1336\u001b[39m         observed=\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[32m   1337\u001b[39m         dropna=\u001b[38;5;28mself\u001b[39m.dropna,\n\u001b[32m   1338\u001b[39m     )\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1341\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'job_title'"
     ]
    }
   ],
   "source": [
    "jda=test.groupby(['job_title']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0478e766-1afb-4a18-84c6-4ba6ee6b2e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e6e05-8e61-4283-8353-392e15a63641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4c9f6-4f87-4d00-9283-91b596ec742f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c079cf-aaa5-4d3c-837b-b123dad610e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e16070-af59-40ac-b358-ff141d044795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        filename  \\\n",
      "0                        pdf1_data_scientist.pdf   \n",
      "1                         pdf2_data_engineer.pdf   \n",
      "2                          pdf3_data_analyst.pdf   \n",
      "3                  pdf4_full_stack_developer.pdf   \n",
      "4                     pdf5_software_engineer.pdf   \n",
      "5               pdf6_python_django_developer.pdf   \n",
      "6                           pdf7_QA_engineer.pdf   \n",
      "7                       pdf8_quality_analyst.pdf   \n",
      "8  pdf9_cyber_security_consultant_specialist.pdf   \n",
      "\n",
      "                                         description  \n",
      "0  data scientist ascendion bangalore urban updat...  \n",
      "1  data engineer ascendion bangalore urban update...  \n",
      "2  data analyst h m bengaluru updated on sep 3 20...  \n",
      "3  full stack developer d square consulting servi...  \n",
      "4  software engineer microsoft pan india updated ...  \n",
      "5  python django developer vegastack peerxp banga...  \n",
      "6  qa engineer adp chennai updated on sep 1 2025 ...  \n",
      "7  quality analyst evon technology dehradun updat...  \n",
      "8  cyber security consultant specialist hsbc pune...  \n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79da19ba-45e9-4d23-8699-8349a9676d78",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = test.to_csv(\u001b[33m'\u001b[39m\u001b[33moutput.csv\u001b[39m\u001b[33m'\u001b[39m,index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter).to_csv(\n\u001b[32m   3987\u001b[39m     path_or_buf,\n\u001b[32m   3988\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   3989\u001b[39m     sep=sep,\n\u001b[32m   3990\u001b[39m     encoding=encoding,\n\u001b[32m   3991\u001b[39m     errors=errors,\n\u001b[32m   3992\u001b[39m     compression=compression,\n\u001b[32m   3993\u001b[39m     quoting=quoting,\n\u001b[32m   3994\u001b[39m     columns=columns,\n\u001b[32m   3995\u001b[39m     index_label=index_label,\n\u001b[32m   3996\u001b[39m     mode=mode,\n\u001b[32m   3997\u001b[39m     chunksize=chunksize,\n\u001b[32m   3998\u001b[39m     quotechar=quotechar,\n\u001b[32m   3999\u001b[39m     date_format=date_format,\n\u001b[32m   4000\u001b[39m     doublequote=doublequote,\n\u001b[32m   4001\u001b[39m     escapechar=escapechar,\n\u001b[32m   4002\u001b[39m     storage_options=storage_options,\n\u001b[32m   4003\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m csv_formatter.save()\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m    254\u001b[39m     encoding=\u001b[38;5;28mself\u001b[39m.encoding,\n\u001b[32m    255\u001b[39m     errors=\u001b[38;5;28mself\u001b[39m.errors,\n\u001b[32m    256\u001b[39m     compression=\u001b[38;5;28mself\u001b[39m.compression,\n\u001b[32m    257\u001b[39m     storage_options=\u001b[38;5;28mself\u001b[39m.storage_options,\n\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Conda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'output.csv'"
     ]
    }
   ],
   "source": [
    "df = test.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401d05e-c9c9-4700-9e7f-76062faed76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
